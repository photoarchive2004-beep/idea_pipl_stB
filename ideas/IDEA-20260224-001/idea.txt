Тема: как оценивать надежность LLM/ChatGPT в научных обзорах и “evidence-based” пайплайнах.

Текст идеи:
Нужно собрать литературу о том, как использовать большие языковые модели для научных обзоров так, чтобы минимизировать ошибки: оценка галлюцинаций, методы верификации источников, RAG и связанные подходы, LLM-assisted screening в систематических обзорах, автоматизация PRISMA-подобных шагов, метрики качества (precision/recall при отборе статей, factuality), практики воспроизводимости. Хочу найти как эмпирические сравнения, так и методические рекомендации.